{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Du Chaos √† MLflow : Un Parcours Guid√©\n",
    "\n",
    "## Objectif du Workshop\n",
    "\n",
    "Vous venez d'exp√©rimenter le **notebook chaotique** (`01_messy_notebook.ipynb`). Vous avez probablement remarqu√© :\n",
    "\n",
    "- \"Attends, c'√©tait lequel le meilleur mod√®le d√©j√†?\"\n",
    "- M√©triques √©parpill√©es dans les cellules, difficiles √† comparer\n",
    "- Aucun moyen de reproduire exactement les r√©sultats\n",
    "- Tracking manuel dans des tableaux markdown (que vous avez oubli√© de mettre √† jour)\n",
    "\n",
    "**Dans ce notebook, nous allons corriger tout √ßa avec MLflow.**\n",
    "\n",
    "---\n",
    "\n",
    "## Comment fonctionne ce notebook\n",
    "\n",
    "Nous allons progressivement augmenter la difficult√© :\n",
    "\n",
    "| Partie | Style | Vous allez... |\n",
    "|--------|-------|---------------|\n",
    "| **Partie 1** | Enti√®rement guid√© | Ex√©cuter le code, observer, apprendre les concepts |\n",
    "| **Partie 2** | R√©v√©lation progressive | Deviner ce qui est n√©cessaire, puis voir la solution |\n",
    "| **Partie 3** | Compl√©ter les blancs | Compl√©ter le code vous-m√™me |\n",
    "\n",
    "**R√©f√©rence** : Voir `02_mlflow_organized.ipynb` pour la solution compl√®te.\n",
    "\n",
    "**Cheatsheet** : Voir `../docs/mlflow_cheatsheet.md` pour une r√©f√©rence rapide.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Pr√©requis\n\nAvant de commencer, assurez-vous que :\n1. Le serveur MLflow est en cours d'ex√©cution : `docker-compose up -d` (depuis la racine du projet)\n2. V√©rifiez que http://localhost:5000 est accessible\n\n> ‚ö†Ô∏è **Utilisateurs Mac** : Le port 5000 est utilis√© par AirPlay Receiver sur macOS Monterey+.\n> Si vous avez une erreur de connexion, modifiez `MLFLOW_PORT=5050` dans votre fichier `.env`\n> et utilisez `http://localhost:5050` partout o√π vous voyez `localhost:5000`."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup : Charger les donn√©es du notebook chaotique\n",
    "\n",
    "D'abord, reproduisons la m√™me pr√©paration de donn√©es que dans le notebook chaotique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports termin√©s!\n"
     ]
    }
   ],
   "source": [
    "# Imports standards (identiques au notebook chaotique)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Imports termin√©s!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donn√©es pr√™tes : 4000 train, 1000 test √©chantillons\n",
      "Features : 13\n"
     ]
    }
   ],
   "source": [
    "# Charger et pr√©parer les donn√©es (identique au notebook chaotique)\n",
    "df = pd.read_csv('../data/customer_data.csv')\n",
    "\n",
    "# Feature engineering\n",
    "df['recency_frequency_ratio'] = df['recency_days'] / (df['frequency'] + 1)\n",
    "df['monetary_per_order'] = df['monetary_value'] / (df['total_orders'] + 1)\n",
    "df['order_frequency'] = df['total_orders'] / (df['days_since_signup'] + 1)\n",
    "df['support_per_order'] = df['support_tickets'] / (df['total_orders'] + 1)\n",
    "df['r_score'] = pd.qcut(df['recency_days'], q=5, labels=[5, 4, 3, 2, 1]).astype(int)\n",
    "df['f_score'] = pd.qcut(df['frequency'].rank(method='first'), q=5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "df['m_score'] = pd.qcut(df['monetary_value'].rank(method='first'), q=5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "df['rfm_score'] = df['r_score'] + df['f_score'] + df['m_score']\n",
    "\n",
    "# D√©finir les features\n",
    "FEATURE_COLS = [\n",
    "    'recency_days', 'frequency', 'monetary_value', 'avg_order_value',\n",
    "    'days_since_signup', 'total_orders', 'support_tickets', 'age',\n",
    "    'recency_frequency_ratio', 'monetary_per_order', 'order_frequency',\n",
    "    'support_per_order', 'rfm_score'\n",
    "]\n",
    "\n",
    "X = df[FEATURE_COLS]\n",
    "y = df['churned']\n",
    "\n",
    "# S√©paration train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Donn√©es pr√™tes : {len(X_train)} train, {len(X_test)} test √©chantillons\")\n",
    "print(f\"Features : {len(FEATURE_COLS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PARTIE 1 : Enti√®rement Guid√©\n",
    "\n",
    "## 1.1 Qu'est-ce que MLflow ?\n",
    "\n",
    "MLflow est une plateforme open-source pour g√©rer le **cycle de vie complet du ML**. Elle a 4 composants principaux :\n",
    "\n",
    "### 1. **Tracking** (notre focus principal aujourd'hui)\n",
    "Enregistrer et requ√™ter les exp√©riences : param√®tres, m√©triques, artefacts et versions du code.\n",
    "- *\"Quels hyperparam√®tres j'ai utilis√© pour mon meilleur mod√®le ?\"*\n",
    "- *\"Comparer l'accuracy sur 50 runs\"*\n",
    "\n",
    "### 2. **Models**\n",
    "Packager les mod√®les ML dans un format standard pour le d√©ploiement sur diverses plateformes (Docker, Kubernetes, services cloud, etc.).\n",
    "- *\"D√©ployer ce mod√®le sklearn comme API REST\"*\n",
    "- *\"Convertir mon mod√®le pour de l'inf√©rence batch\"*\n",
    "\n",
    "### 3. **Model Registry** (on va l'utiliser aussi)\n",
    "Store centralis√© de mod√®les avec versioning, transitions d'√©tat (Staging ‚Üí Production), et annotations.\n",
    "- *\"Promouvoir le mod√®le v3 en production\"*\n",
    "- *\"Qui a approuv√© cette version du mod√®le ?\"*\n",
    "\n",
    "### 4. **Projects**\n",
    "Packager le code et les d√©pendances pour des ex√©cutions reproductibles sur n'importe quelle plateforme.\n",
    "- *\"Ex√©cuter cette exp√©rience avec exactement le m√™me environnement\"*\n",
    "- *\"Partager mon pipeline avec l'√©quipe\"*\n",
    "\n",
    "---\n",
    "\n",
    "### MLflow pour les LLMs (Bonus)\n",
    "\n",
    "MLflow supporte maintenant les **applications LLM/GenAI** :\n",
    "- **Tracing** : D√©bugger et monitorer les appels LLM, pipelines RAG, et agents multi-√©tapes\n",
    "- **√âvaluation** : Benchmarker les outputs LLM avec des m√©triques int√©gr√©es\n",
    "- **D√©ploiement** : Servir les mod√®les LLM avec la m√™me infrastructure de serving\n",
    "\n",
    "*On ne couvre pas le tracking LLM aujourd'hui, mais sachez que MLflow fonctionne au-del√† du ML traditionnel !*\n",
    "\n",
    "---\n",
    "\n",
    "**Aujourd'hui on se concentre sur Tracking et Registry** - les fondations pour la gestion d'exp√©riences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Se connecter √† MLflow\n",
    "\n",
    "D'abord, on importe MLflow et on lui indique o√π se trouve notre serveur de tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version MLflow : 3.9.0\n"
     ]
    }
   ],
   "source": [
    "# NOUVEAU : Importer MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "print(f\"Version MLflow : {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le serveur MLflow fonctionne !\n"
     ]
    }
   ],
   "source": [
    "# Se connecter au serveur MLflow (qui tourne dans Docker)\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "# V√©rifier la connexion\n",
    "import requests\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:5000/health\")\n",
    "    if response.status_code == 200:\n",
    "        print(\"Le serveur MLflow fonctionne !\")\n",
    "    else:\n",
    "        print(f\"Le serveur a r√©pondu avec : {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"Impossible de se connecter au serveur MLflow : {e}\")\n",
    "    print(\"Ex√©cutez 'docker-compose up -d' depuis la racine du projet !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Cr√©er une Exp√©rience\n",
    "\n",
    "Une **Exp√©rience** regroupe les runs associ√©s ensemble. Pensez-y comme un dossier de projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/20 05:37:11 INFO mlflow.tracking.fluent: Experiment with name 'workshop-churn-learning' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation de l'exp√©rience : workshop-churn-learning\n",
      "Voir sur : http://localhost:5000\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er ou r√©cup√©rer une exp√©rience\n",
    "experiment_name = \"workshop-churn-learning\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"Utilisation de l'exp√©rience : {experiment_name}\")\n",
    "print(f\"Voir sur : http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Votre Premier Run MLflow\n",
    "\n",
    "Un **Run** est une ex√©cution unique de votre code d'entra√Ænement. Dans un run, vous pouvez logger :\n",
    "\n",
    "- **Parameters** : Les entr√©es (hyperparam√®tres, config)\n",
    "- **Metrics** : Les sorties (accuracy, loss, F1)\n",
    "- **Artifacts** : Les fichiers (mod√®les, graphiques, donn√©es)\n",
    "- **Tags** : Les m√©tadonn√©es (auteur, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7810\n",
      "Score F1 : 0.7763\n",
      "\n",
      "Run enregistr√© dans MLflow !\n",
      "Allez sur http://localhost:5000 pour le voir !\n",
      "üèÉ View run mon-premier-run-mlflow at: http://localhost:5000/#/experiments/1/runs/35588a0a49ad4838b29d7623fc1d8bff\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# Entra√Ænons un mod√®le simple et LOGGONS TOUT\n",
    "\n",
    "# D√©marrer un run\n",
    "with mlflow.start_run(run_name=\"mon-premier-run-mlflow\"):\n",
    "    \n",
    "    # 1. LOGGER LES PARAM√àTRES (entr√©es de votre mod√®le)\n",
    "    mlflow.log_param(\"model_type\", \"RandomForest\")\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"max_depth\", 10)\n",
    "    \n",
    "    # 2. Entra√Æner le mod√®le (m√™me code qu'avant)\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 3. Faire des pr√©dictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 4. LOGGER LES M√âTRIQUES (sorties/r√©sultats)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"f1\", f1)\n",
    "    \n",
    "    print(f\"Accuracy : {accuracy:.4f}\")\n",
    "    print(f\"Score F1 : {f1:.4f}\")\n",
    "    print(\"\\nRun enregistr√© dans MLflow !\")\n",
    "    print(\"Allez sur http://localhost:5000 pour le voir !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allez voir l'UI MLflow !\n",
    "\n",
    "1. Ouvrez http://localhost:5000\n",
    "2. Cliquez sur l'exp√©rience \"workshop-churn-learning\"\n",
    "3. Cliquez sur \"mon-premier-run-mlflow\"\n",
    "4. Voyez vos param√®tres et m√©triques !\n",
    "\n",
    "**C'est d√©j√† mieux que le notebook chaotique** - vos r√©sultats sont sauvegard√©s et organis√©s !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Logger plusieurs m√©triques √† la fois\n",
    "\n",
    "Au lieu d'appeler `log_metric` plusieurs fois, vous pouvez logger un dictionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toutes les m√©triques logg√©es !\n",
      "üèÉ View run exemple-metriques-multiples at: http://localhost:5000/#/experiments/1/runs/558ad9bfd4624f52b6af5a92fb0f56a7\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# Plus efficace : logger plusieurs m√©triques d'un coup\n",
    "with mlflow.start_run(run_name=\"exemple-metriques-multiples\"):\n",
    "    \n",
    "    # Logger les params en dict\n",
    "    mlflow.log_params({\n",
    "        \"model_type\": \"RandomForest\",\n",
    "        \"n_estimators\": 150,\n",
    "        \"max_depth\": 12\n",
    "    })\n",
    "    \n",
    "    # Entra√Æner\n",
    "    model = RandomForestClassifier(n_estimators=150, max_depth=12, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Logger les m√©triques en dict\n",
    "    mlflow.log_metrics({\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred),\n",
    "        \"recall\": recall_score(y_test, y_pred),\n",
    "        \"f1\": f1_score(y_test, y_pred)\n",
    "    })\n",
    "    \n",
    "    print(\"Toutes les m√©triques logg√©es !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PARTIE 2 : R√©v√©lation Progressive\n",
    "\n",
    "Maintenant vous comprenez les bases. Ajoutons plus de fonctionnalit√©s MLflow.\n",
    "\n",
    "**Format** : Je vous montre un probl√®me, vous r√©fl√©chissez √† ce qui est n√©cessaire, puis je r√©v√®le la solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Probl√®me : Sauvegarder le mod√®le\n",
    "\n",
    "Dans le notebook chaotique, on avait :\n",
    "```python\n",
    "# sauvegarder le mod√®le? je sais pas o√π\n",
    "# import pickle\n",
    "# with open('model.pkl', 'wb') as f:\n",
    "#     pickle.dump(best_rf, f)\n",
    "```\n",
    "\n",
    "**Question** : Comment peut-on sauvegarder le mod√®le AVEC le run, pour qu'il soit toujours li√© √† ses m√©triques ?\n",
    "\n",
    "*R√©fl√©chissez-y... puis ex√©cutez la cellule suivante pour voir la solution.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/20 05:37:44 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod√®le sauvegard√© comme artefact !\n",
      "V√©rifiez l'onglet 'Artifacts' dans l'UI MLflow\n",
      "üèÉ View run avec-artefact-modele at: http://localhost:5000/#/experiments/1/runs/333c8fcf4ea44402a955464f54a44813\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION : Utiliser mlflow.sklearn.log_model()\n",
    "\n",
    "with mlflow.start_run(run_name=\"avec-artefact-modele\"):\n",
    "    \n",
    "    mlflow.log_params({\"n_estimators\": 100, \"max_depth\": 10})\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"f1\": f1_score(y_test, y_pred)\n",
    "    })\n",
    "    \n",
    "    # LOGGER LE MOD√àLE - il est maintenant sauvegard√© avec ce run !\n",
    "    mlflow.sklearn.log_model(model, name=\"model\")\n",
    "    \n",
    "    print(\"Mod√®le sauvegard√© comme artefact !\")\n",
    "    print(\"V√©rifiez l'onglet 'Artifacts' dans l'UI MLflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Probl√®me : Sauvegarder les graphiques\n",
    "\n",
    "Dans le notebook chaotique, on cr√©ait des matrices de confusion et des graphiques d'importance des features.\n",
    "Mais ils s'affichaient juste dans le notebook - pas sauvegard√©s nulle part !\n",
    "\n",
    "**Question** : Comment peut-on sauvegarder une figure matplotlib comme artefact ?\n",
    "\n",
    "*R√©fl√©chissez... puis r√©v√©lez.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphique sauvegard√© comme artefact !\n",
      "üèÉ View run avec-graphiques at: http://localhost:5000/#/experiments/1/runs/b427ce16f2804ebe91ca2c667794f8a1\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION : Utiliser mlflow.log_figure()\n",
    "\n",
    "with mlflow.start_run(run_name=\"avec-graphiques\"):\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mlflow.log_metrics({\"accuracy\": accuracy_score(y_test, y_pred)})\n",
    "    \n",
    "    # Cr√©er le graphique de matrice de confusion\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_xlabel('Pr√©dit')\n",
    "    ax.set_ylabel('R√©el')\n",
    "    ax.set_title('Matrice de Confusion')\n",
    "    \n",
    "    # LOGGER LA FIGURE - pas de fichier local cr√©√© !\n",
    "    mlflow.log_figure(fig, \"matrice_confusion.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Graphique sauvegard√© comme artefact !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Probl√®me : Le probl√®me du Scaler\n",
    "\n",
    "Pour la R√©gression Logistique, on doit normaliser les features :\n",
    "```python\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "```\n",
    "\n",
    "**Probl√®me** : Au moment de l'inf√©rence, on a besoin du M√äME scaler. Si on ne le sauvegarde pas, on ne peut pas faire de pr√©dictions correctes plus tard !\n",
    "\n",
    "**Question** : Comment sauvegarder le scaler avec le mod√®le ?\n",
    "\n",
    "*R√©fl√©chissez... puis r√©v√©lez.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/20 05:38:08 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod√®le + scaler sauvegard√©s !\n",
      "V√©rifiez les artefacts : preprocessing/scaler.pkl\n",
      "üèÉ View run logistique-avec-scaler at: http://localhost:5000/#/experiments/1/runs/701ec316385f414caa10b8387fe73807\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION : Sauvegarder le scaler comme artefact\n",
    "import joblib\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "with mlflow.start_run(run_name=\"logistique-avec-scaler\"):\n",
    "    \n",
    "    # Normaliser les donn√©es\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Sauvegarder le scaler comme artefact (avec tempfile pour √©viter les fichiers locaux)\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        scaler_path = os.path.join(tmpdir, \"scaler.pkl\")\n",
    "        joblib.dump(scaler, scaler_path)\n",
    "        mlflow.log_artifact(scaler_path, artifact_path=\"preprocessing\")\n",
    "    \n",
    "    # Entra√Æner le mod√®le\n",
    "    model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    mlflow.log_metrics({\"accuracy\": accuracy_score(y_test, y_pred)})\n",
    "    mlflow.sklearn.log_model(model, name=\"model\")\n",
    "    \n",
    "    # Tag pour se rappeler que ce mod√®le n√©cessite un scaling\n",
    "    mlflow.set_tag(\"requires_scaling\", \"true\")\n",
    "    \n",
    "    print(\"Mod√®le + scaler sauvegard√©s !\")\n",
    "    print(\"V√©rifiez les artefacts : preprocessing/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Note : En production, pr√©f√©rez sklearn Pipeline\n",
    "\n",
    "L'approche ci-dessus (sauvegarder scaler.pkl s√©par√©ment) est utile pour comprendre le probl√®me, mais en production il existe une meilleure solution : **sklearn Pipeline**.\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Combiner scaler + mod√®le en UN SEUL objet\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "pipeline.fit(X_train, y)\n",
    "mlflow.sklearn.log_model(pipeline, name=\"model\")  # UN seul artefact !\n",
    "\n",
    "# √Ä l'inf√©rence : pipeline.predict(X)  # Le scaling est automatique !\n",
    "```\n",
    "\n",
    "**Avantages :** Un seul artefact, impossible d'oublier le scaling, inf√©rence simplifi√©e.\n",
    "\n",
    "Voir `02_mlflow_organized.ipynb` section 8.1 pour un exemple complet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Probl√®me : Comparer les runs\n",
    "\n",
    "Dans le notebook chaotique :\n",
    "```python\n",
    "# ok j'abandonne d'essayer de suivre toutes ces exp√©riences\n",
    "# c'√©tait lequel le meilleur? je crois que c'√©tait celui de grid search?\n",
    "```\n",
    "\n",
    "**Question** : Comment trouver programmatiquement le meilleur run ?\n",
    "\n",
    "*R√©fl√©chissez... puis r√©v√©lez.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 des runs par accuracy :\n",
      "============================================================\n",
      "logistique-avec-scaler: accuracy=0.8050, f1=0.0000\n",
      "exemple-metriques-multiples: accuracy=0.7870, f1=0.7815\n",
      "avec-artefact-modele: accuracy=0.7810, f1=0.7763\n",
      "mon-premier-run-mlflow: accuracy=0.7810, f1=0.7763\n",
      "avec-graphiques: accuracy=0.7770, f1=0.0000\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION : Utiliser le Client MLflow pour rechercher les runs\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "\n",
    "# Rechercher les runs, tri√©s par accuracy (d√©croissant)\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\"metrics.accuracy DESC\"],\n",
    "    max_results=5\n",
    ")\n",
    "\n",
    "print(\"Top 5 des runs par accuracy :\")\n",
    "print(\"=\" * 60)\n",
    "for run in runs:\n",
    "    acc = run.data.metrics.get('accuracy', 0)\n",
    "    f1 = run.data.metrics.get('f1', 0)\n",
    "    print(f\"{run.info.run_name}: accuracy={acc:.4f}, f1={f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PARTIE 3 : Compl√©ter les blancs\n",
    "\n",
    "Maintenant c'est √† vous ! Compl√©tez le code dans les cellules suivantes.\n",
    "\n",
    "**Aide** : R√©f√©rez-vous au cheatsheet dans `../docs/mlflow_cheatsheet.md`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Exercice : Logger un mod√®le Gradient Boosting\n",
    "\n",
    "Compl√©tez le code pour entra√Æner et logger un mod√®le Gradient Boosting avec :\n",
    "- Param√®tres : n_estimators, learning_rate, max_depth\n",
    "- M√©triques : accuracy, precision, recall, f1\n",
    "- Artefact : le mod√®le entra√Æn√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercice termin√© ! V√©rifiez l'UI MLflow.\n",
      "üèÉ View run exercice-gradient-boosting at: http://localhost:5000/#/experiments/1/runs/1bf21726b72c40f7892579d9241849ee\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# EXERCICE : Compl√©tez ce code\n",
    "\n",
    "with mlflow.start_run(run_name=\"exercice-gradient-boosting\"):\n",
    "    \n",
    "    # TODO : Logger ces param√®tres\n",
    "    n_estimators = 100\n",
    "    learning_rate = 0.1\n",
    "    max_depth = 5\n",
    "    \n",
    "    # mlflow.log_params({...})  # <-- Compl√©tez ceci\n",
    "    \n",
    "    # Entra√Æner le mod√®le\n",
    "    model = GradientBoostingClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # TODO : Calculer et logger les m√©triques\n",
    "    # mlflow.log_metrics({...})  # <-- Compl√©tez ceci\n",
    "    \n",
    "    # TODO : Logger le mod√®le\n",
    "    # mlflow.sklearn.log_model(...)  # <-- Compl√©tez ceci\n",
    "    \n",
    "    print(\"Exercice termin√© ! V√©rifiez l'UI MLflow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Cliquez pour r√©v√©ler la solution</summary>\n",
    "\n",
    "```python\n",
    "with mlflow.start_run(run_name=\"exercice-gradient-boosting\"):\n",
    "    \n",
    "    n_estimators = 100\n",
    "    learning_rate = 0.1\n",
    "    max_depth = 5\n",
    "    \n",
    "    mlflow.log_params({\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"max_depth\": max_depth\n",
    "    })\n",
    "    \n",
    "    model = GradientBoostingClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred),\n",
    "        \"recall\": recall_score(y_test, y_pred),\n",
    "        \"f1\": f1_score(y_test, y_pred)\n",
    "    })\n",
    "    \n",
    "    mlflow.sklearn.log_model(model, name=\"model\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Exercice : Ajouter des tags et une matrice de confusion\n",
    "\n",
    "Am√©liorez votre run avec :\n",
    "- Tags : author (votre nom), model_type\n",
    "- Un graphique de matrice de confusion comme artefact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercice termin√© !\n",
      "üèÉ View run exercice-avec-tags-et-graphique at: http://localhost:5000/#/experiments/1/runs/59f9d2980784421a93261bd7ecac3abe\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# EXERCICE : Compl√©tez ce code\n",
    "\n",
    "with mlflow.start_run(run_name=\"exercice-avec-tags-et-graphique\"):\n",
    "    \n",
    "    # TODO : Ajouter des tags\n",
    "    # mlflow.set_tag(\"author\", \"...\")  # <-- Votre nom\n",
    "    # mlflow.set_tag(\"model_type\", \"...\")  # <-- Type de mod√®le\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    # TODO : Cr√©er et logger la matrice de confusion\n",
    "    # cm = confusion_matrix(y_test, y_pred)\n",
    "    # fig, ax = plt.subplots(...)\n",
    "    # sns.heatmap(...)\n",
    "    # mlflow.log_figure(...)  # <-- Compl√©tez ceci\n",
    "    # plt.close()\n",
    "    \n",
    "    print(\"Exercice termin√© !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 D√©fi : Trouver et charger le meilleur mod√®le\n",
    "\n",
    "Utilisez le Client MLflow pour :\n",
    "1. Trouver le run avec la meilleure accuracy\n",
    "2. Charger le mod√®le de ce run\n",
    "3. Faire des pr√©dictions sur de nouvelles donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√âFI : Compl√©tez ce code\n",
    "\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "\n",
    "# TODO : Rechercher le meilleur run par accuracy\n",
    "# best_runs = client.search_runs(\n",
    "#     experiment_ids=[...],\n",
    "#     order_by=[...],\n",
    "#     max_results=1\n",
    "# )\n",
    "\n",
    "# if best_runs:\n",
    "#     best_run = best_runs[0]\n",
    "#     print(f\"Meilleur run : {best_run.info.run_name}\")\n",
    "#     print(f\"Accuracy : {best_run.data.metrics.get('accuracy', 0):.4f}\")\n",
    "    \n",
    "#     # TODO : Charger le mod√®le\n",
    "#     # model_uri = f\"runs:/{best_run.info.run_id}/model\"\n",
    "#     # loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "    \n",
    "#     # TODO : Faire des pr√©dictions\n",
    "#     # predictions = loaded_model.predict(X_test[:5])\n",
    "#     # print(f\"Exemples de pr√©dictions : {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PARTIE 4 : Serving & Inf√©rence\n",
    "\n",
    "Vous savez d√©j√† servir des mod√®les avec joblib + FastAPI. Voyons comment MLflow simplifie cela."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Enregistrer un mod√®le\n",
    "\n",
    "Avant de servir, enregistrons notre meilleur mod√®le dans le Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/20 05:38:23 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod√®le logg√©. Run ID : 3a9c803f082449ad958e9dfd7bdc6da2\n",
      "üèÉ View run modele-pour-registry at: http://localhost:5000/#/experiments/1/runs/3a9c803f082449ad958e9dfd7bdc6da2\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# D'abord, entra√Ænons un mod√®le qu'on veut enregistrer\n",
    "with mlflow.start_run(run_name=\"modele-pour-registry\") as run:\n",
    "    \n",
    "    mlflow.log_params({\"n_estimators\": 200, \"max_depth\": 12})\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=200, max_depth=12, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"f1\": f1_score(y_test, y_pred)\n",
    "    })\n",
    "    \n",
    "    # Logger le mod√®le\n",
    "    mlflow.sklearn.log_model(model, name=\"model\")\n",
    "    \n",
    "    # Sauvegarder run_id pour l'enregistrement\n",
    "    run_id = run.info.run_id\n",
    "    print(f\"Mod√®le logg√©. Run ID : {run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'churn-predictor'.\n",
      "2026/02/20 05:38:24 WARNING mlflow.tracking._model_registry.fluent: Run with id 3a9c803f082449ad958e9dfd7bdc6da2 has no artifacts at artifact path 'model', registering model based on models:/m-d2cf0c8e2f4a4d07af5b9c6c8d4ac021 instead\n",
      "2026/02/20 05:38:24 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: churn-predictor, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod√®le enregistr√© : churn-predictor\n",
      "Version : 1\n",
      "\n",
      "Voir dans l'UI : http://localhost:5000/#/models/churn-predictor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'churn-predictor'.\n"
     ]
    }
   ],
   "source": [
    "# Enregistrer le mod√®le dans le Model Registry\n",
    "model_name = \"churn-predictor\"\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "# Enregistrer !\n",
    "model_version = mlflow.register_model(model_uri, model_name)\n",
    "\n",
    "print(f\"Mod√®le enregistr√© : {model_name}\")\n",
    "print(f\"Version : {model_version.version}\")\n",
    "print(f\"\\nVoir dans l'UI : http://localhost:5000/#/models/{model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Charger un mod√®le depuis le Registry\n",
    "\n",
    "Au lieu de `joblib.load('model.pkl')`, vous pouvez charger par nom et version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples de pr√©dictions : [0 1 0 1 1]\n",
      "\n",
      "Mod√®le charg√© depuis le registry : churn-predictor/latest\n"
     ]
    }
   ],
   "source": [
    "# Charger le mod√®le depuis le registry - comparez avec ce que vous connaissez !\n",
    "\n",
    "# ANCIENNE M√âTHODE (ce que vous connaissez d√©j√†) :\n",
    "# model = joblib.load('model.pkl')  # O√π est-il ? Quelle version ?\n",
    "\n",
    "# M√âTHODE MLFLOW :\n",
    "# Charger la derni√®re version\n",
    "loaded_model = mlflow.sklearn.load_model(f\"models:/{model_name}/latest\")\n",
    "\n",
    "# Ou charger une version sp√©cifique\n",
    "# loaded_model = mlflow.sklearn.load_model(f\"models:/{model_name}/1\")\n",
    "\n",
    "# Faire des pr√©dictions - identique √† avant !\n",
    "sample_predictions = loaded_model.predict(X_test[:5])\n",
    "print(f\"Exemples de pr√©dictions : {sample_predictions}\")\n",
    "print(f\"\\nMod√®le charg√© depuis le registry : {model_name}/latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Servir le mod√®le comme API REST\n",
    "\n",
    "> ‚ö†Ô∏è **Pr√©requis** : Vous devez avoir ex√©cut√© les sections 4.1 et 4.2 pour enregistrer le mod√®le dans le Registry avant de pouvoir le servir.\n",
    "\n",
    "Vous savez comment servir des mod√®les avec FastAPI :\n",
    "\n",
    "```python\n",
    "# ANCIENNE M√âTHODE - FastAPI + joblib\n",
    "from fastapi import FastAPI\n",
    "import joblib\n",
    "\n",
    "app = FastAPI()\n",
    "model = joblib.load('model.pkl')\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(data: dict):\n",
    "    X = pd.DataFrame([data])\n",
    "    return {\"prediction\": model.predict(X).tolist()}\n",
    "```\n",
    "\n",
    "**MLflow fait √ßa en une commande :**\n",
    "\n",
    "```bash\n",
    "# Windows (PowerShell)\n",
    "$env:MLFLOW_TRACKING_URI=\"http://localhost:5000\"; mlflow models serve -m \"models:/churn-predictor/latest\" -p 5001 --no-conda\n",
    "\n",
    "# Windows (CMD)\n",
    "set MLFLOW_TRACKING_URI=http://localhost:5000 && mlflow models serve -m \"models:/churn-predictor/latest\" -p 5001 --no-conda\n",
    "\n",
    "# Linux/Mac\n",
    "MLFLOW_TRACKING_URI=http://localhost:5000 mlflow models serve -m \"models:/churn-predictor/latest\" -p 5001 --no-conda\n",
    "```\n",
    "\n",
    "> üí° **Important** : La variable `MLFLOW_TRACKING_URI` indique √† la CLI o√π trouver le serveur MLflow. Sans elle, la commande ne sait pas o√π chercher le mod√®le !\n",
    "\n",
    "> ‚ö†Ô∏è **Si vous utilisez `uv` pour g√©rer votre environnement virtuel** et obtenez l'erreur \"failed to canonicalize script path\", utilisez cette commande √† la place :\n",
    "> ```bash\n",
    "> $env:MLFLOW_TRACKING_URI=\"http://localhost:5000\"; uv run python -m mlflow models serve -m \"models:/churn-predictor/latest\" -p 5001 --no-conda\n",
    "> ```\n",
    "\n",
    "C'est tout. Pas besoin de code FastAPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier que le mod√®le est enregistr√© avant de le servir\n",
    "from mlflow.tracking import MlflowClient\n",
    "import platform\n",
    "\n",
    "client = MlflowClient()\n",
    "model_name = \"churn-predictor\"\n",
    "\n",
    "try:\n",
    "    versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "    if versions:\n",
    "        print(f\"‚úÖ Mod√®le '{model_name}' trouv√© avec {len(versions)} version(s)\")\n",
    "        print(f\"   Derni√®re version : {versions[0].version}\")\n",
    "        print(f\"\n",
    "Vous pouvez maintenant servir le mod√®le :\")\n",
    "        if platform.system() == \"Windows\":\n",
    "            print(f'\n",
    "   # PowerShell:')\n",
    "            print(f'   $env:MLFLOW_TRACKING_URI=\"http://localhost:5000\"; mlflow models serve -m \"models:/{model_name}/latest\" -p 5001 --no-conda')\n",
    "            print(f'\n",
    "   # Si erreur \"failed to canonicalize script path\" (avec uv):')\n",
    "            print(f'   $env:MLFLOW_TRACKING_URI=\"http://localhost:5000\"; uv run python -m mlflow models serve -m \"models:/{model_name}/latest\" -p 5001 --no-conda')\n",
    "        else:\n",
    "            print(f'\n",
    "   MLFLOW_TRACKING_URI=http://localhost:5000 mlflow models serve -m \"models:/{model_name}/latest\" -p 5001 --no-conda')\n",
    "    else:\n",
    "        print(f\"‚ùå Mod√®le '{model_name}' non trouv√© dans le Registry\")\n",
    "        print(\"   ‚Üí Ex√©cutez d'abord les sections 4.1 et 4.2 !\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur : {e}\")\n",
    "    print(\"   ‚Üí Ex√©cutez d'abord les sections 4.1 et 4.2 !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si vous ex√©cutez la commande serve ci-dessus, vous pouvez l'appeler comme ceci :\n",
    "# (C'est le m√™me pattern que vous connaissez avec FastAPI !)\n",
    "\n",
    "import requests\n",
    "\n",
    "# Donn√©es exemple pour la pr√©diction\n",
    "sample_data = X_test.head(3).to_dict(orient='split')\n",
    "\n",
    "# D√©commentez quand le serveur tourne :\n",
    "# response = requests.post(\n",
    "#     \"http://localhost:5001/invocations\",\n",
    "#     json={\"dataframe_split\": sample_data}\n",
    "# )\n",
    "# print(response.json())\n",
    "\n",
    "print(\"Pour tester le serving :\")\n",
    "print(\"1. Ouvrez un terminal\")\n",
    "print(\"2. Ex√©cutez la commande affich√©e dans la cellule pr√©c√©dente\")\n",
    "print(\"   (N'oubliez pas MLFLOW_TRACKING_URI !)\")\n",
    "print(\"3. D√©commentez le code ci-dessus et ex√©cutez cette cellule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Inf√©rence Batch (Charger depuis le Registry)\n",
    "\n",
    "Pour des pr√©dictions batch dans un pipeline, chargez et pr√©disez simplement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr√©dictions batch pour 100 clients :\n",
      "   customer_id  churn_probability  churn_predicted\n",
      "0            1           0.827594                1\n",
      "1            2           0.197167                0\n",
      "2            3           0.939545                1\n",
      "3            4           0.079333                0\n",
      "4            5           0.814197                1\n",
      "5            6           0.276842                0\n",
      "6            7           0.338037                0\n",
      "7            8           0.159866                0\n",
      "8            9           0.954640                1\n",
      "9           10           0.871626                1\n"
     ]
    }
   ],
   "source": [
    "# Inf√©rence batch - c'est ce que les orchestrateurs vont faire !\n",
    "\n",
    "# Charger le mod√®le depuis le registry\n",
    "model = mlflow.sklearn.load_model(f\"models:/{model_name}/latest\")\n",
    "\n",
    "# Charger de nouvelles donn√©es (simuler un batch quotidien)\n",
    "new_customers = df[FEATURE_COLS].head(100)\n",
    "\n",
    "# Pr√©dire\n",
    "predictions = model.predict(new_customers)\n",
    "probabilities = model.predict_proba(new_customers)[:, 1]\n",
    "\n",
    "# Cr√©er les r√©sultats\n",
    "results = pd.DataFrame({\n",
    "    'customer_id': df['customer_id'].head(100),\n",
    "    'churn_probability': probabilities,\n",
    "    'churn_predicted': predictions\n",
    "})\n",
    "\n",
    "print(f\"Pr√©dictions batch pour {len(results)} clients :\")\n",
    "print(results.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Comparaison : Ce que vous connaissez vs MLflow\n",
    "\n",
    "| T√¢che | Manuel (joblib + FastAPI) | MLflow |\n",
    "|-------|---------------------------|--------|\n",
    "| Sauvegarder mod√®le | `joblib.dump(model, 'model_v2.pkl')` | `mlflow.sklearn.log_model(model, name=\"model\")` |\n",
    "| Charger mod√®le | `joblib.load('model_v2.pkl')` | `mlflow.sklearn.load_model(\"models:/name/1\")` |\n",
    "| Versioning | Noms de fichiers manuels (`model_v1.pkl`, `model_v2.pkl`) | Versions automatiques (1, 2, 3...) |\n",
    "| Servir en API | √âcrire du code FastAPI, lancer uvicorn | `mlflow models serve -m models:/name/1` |\n",
    "| Tracker quel mod√®le | Esp√©rer se souvenir / v√©rifier les dates de fichiers | Registry montre version, m√©triques, qui l'a entra√Æn√© |\n",
    "| Rollback | Trouver l'ancien fichier, esp√©rer qu'il marche | `mlflow.sklearn.load_model(\"models:/name/1\")` |\n",
    "\n",
    "**MLflow ne remplace pas vos comp√©tences** - il les enrichit avec le versioning, le tracking et l'automatisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# R√©sum√©\n",
    "\n",
    "## Ce que vous avez appris\n",
    "\n",
    "| Concept | Code |\n",
    "|---------|------|\n",
    "| Se connecter √† MLflow | `mlflow.set_tracking_uri(\"http://localhost:5000\")` |\n",
    "| Cr√©er une exp√©rience | `mlflow.set_experiment(\"name\")` |\n",
    "| D√©marrer un run | `with mlflow.start_run():` |\n",
    "| Logger des param√®tres | `mlflow.log_params({\"key\": value})` |\n",
    "| Logger des m√©triques | `mlflow.log_metrics({\"accuracy\": 0.95})` |\n",
    "| Logger un mod√®le | `mlflow.sklearn.log_model(model, name=\"model\")` |\n",
    "| Logger une figure | `mlflow.log_figure(fig, \"plot.png\")` |\n",
    "| Logger un artefact | `mlflow.log_artifact(\"file.pkl\")` |\n",
    "| D√©finir des tags | `mlflow.set_tag(\"author\", \"me\")` |\n",
    "| Rechercher des runs | `client.search_runs(...)` |\n",
    "| Enregistrer un mod√®le | `mlflow.register_model(uri, \"name\")` |\n",
    "| Charger depuis le registry | `mlflow.sklearn.load_model(\"models:/name/latest\")` |\n",
    "| Servir un mod√®le | `mlflow models serve -m models:/name/1 -p 5001` |\n",
    "\n",
    "## Le Pipeline ML Complet\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  D√âVELOPPER  ‚îÇ ‚Üí  ‚îÇ  ENTRA√éNER   ‚îÇ ‚Üí  ‚îÇ  ENREGISTRER ‚îÇ ‚Üí  ‚îÇ    SERVIR    ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  Notebooks   ‚îÇ    ‚îÇ Orchestrateur‚îÇ    ‚îÇ    Model     ‚îÇ    ‚îÇ  API REST    ‚îÇ\n",
    "‚îÇ Exp√©riences  ‚îÇ    ‚îÇ  + Tracking  ‚îÇ    ‚îÇ   Registry   ‚îÇ    ‚îÇ   ou Batch   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    Partie 1-3         Partie 4           Partie 4           Partie 4\n",
    "```\n",
    "\n",
    "## Prochaines √©tapes\n",
    "\n",
    "**Notebook de r√©f√©rence** : Voir `02_mlflow_organized.ipynb` pour la version compl√®te, pr√™te pour la production.\n",
    "\n",
    "**Orchestrateurs** : Maintenant que vous comprenez MLflow, automatisons ce pipeline !\n",
    "- **Prefect** : Voir `pipelines/workshop/02_prefect/Prefect_Workshop.py` - entra√Æne ET fait de l'inf√©rence\n",
    "- **Dagster** : Voir `pipelines/workshop/03_dagster/Dagster_Workshop.py` - approche centr√©e sur les assets\n",
    "- **Airflow** : Voir `pipelines/workshop/01_airflow/Airflow_Pipeline.py` - standard de l'industrie\n",
    "\n",
    "Les orchestrateurs vont :\n",
    "1. Planifier des runs d'entra√Ænement quotidiens\n",
    "2. Logger tout dans MLflow automatiquement\n",
    "3. Enregistrer les nouvelles versions de mod√®les\n",
    "4. Ex√©cuter l'inf√©rence batch et sauvegarder les pr√©dictions\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Atelier MlFlow_orchestrateur",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}